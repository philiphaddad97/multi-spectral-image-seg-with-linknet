{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3WrqGJIH2GP"
      },
      "source": [
        "### **Summary**\n",
        "In this notebook I loaded the dataset from .mat file,\n",
        "the data is a LARGE photo with 6-Channels.\n",
        "\n",
        "---\n",
        "\n",
        "* 1st Channel is Blue.\n",
        "* 2nd Channel is Green. \n",
        "* 3rd Channel is Red.\n",
        "* 4th, 5th and 6th are Infrared."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uywhsHmxjEhh",
        "outputId": "d67729fa-f578-417b-9678-feb3600cb0f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: patchify in /usr/local/lib/python3.7/dist-packages (0.2.3)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.7/dist-packages (from patchify) (1.21.6)\n"
          ]
        }
      ],
      "source": [
        "from scipy.io import loadmat\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "!pip install patchify\n",
        "from patchify import patchify\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "patch_size = 256\n",
        "file_path = '/content/drive/MyDrive/DS-LAB1/rit18_data.mat'\n",
        "import gc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gOTstsGnOXci",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6045c19-3d3a-40fd-dda0-db418e75d1ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KdIUDBVfjU2L"
      },
      "outputs": [],
      "source": [
        "# file_path = '/content/drive/MyDrive/DS-LAB1/rit18_data.mat'\n",
        "# dataset = loadmat(file_path)\n",
        "\n",
        "# #Load Training Data and Labels\n",
        "# train_data = dataset['train_data']\n",
        "# train_mask = train_data[-1]\n",
        "# train_data = train_data[:6]\n",
        "# train_labels = dataset['train_labels']\n",
        "\n",
        "# #Load Validation Data and Labels\n",
        "# val_data = dataset['val_data']\n",
        "# val_mask = val_data[-1]\n",
        "# val_data = val_data[:6]\n",
        "# val_labels = dataset['val_labels']\n",
        "\n",
        "# #Load Test Data\n",
        "# test_data = dataset['test_data']\n",
        "# test_mask = test_data[-1]\n",
        "# test_data = test_data[:6]\n",
        "\n",
        "# band_centers = dataset['band_centers'][0]\n",
        "# band_center_units = dataset['band_center_units']\n",
        "# classes = dataset['classes']                          \n",
        "\n",
        "# print(\"Train data shape\", train_data.shape)\n",
        "# print(\"Validation data shape\", val_data.shape)\n",
        "# print(\"Test data shape\", test_mask.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-39p4XbHlBAY"
      },
      "outputs": [],
      "source": [
        "def reshape_data(data):\n",
        "  return np.rollaxis(data,0,3)\n",
        "\n",
        "def data2patches(data, shape: tuple, patch_size, scaler = None):\n",
        "  dataset = []\n",
        "  # ------- TO DO ------- solve the reminder size/patch_size pixel issue \n",
        "  # shape is like (patch_size, patch_size, num_of_channels)\n",
        "\n",
        "  patches_img = patchify(data, shape, step=patch_size)\n",
        "\n",
        "  for i in range(patches_img.shape[0]):\n",
        "      for j in range(patches_img.shape[1]):\n",
        "\n",
        "          \n",
        "          single_patch_img = patches_img[i,j,:,:]\n",
        "          \n",
        "          if scaler: \n",
        "            single_patch_img = scaler.fit_transform(single_patch_img.reshape(-1, single_patch_img.shape[-1])).reshape(single_patch_img.shape)\n",
        "            single_patch_img = single_patch_img[0] #Drop the extra unecessary dimension that patchify adds, for data only not for masks       \n",
        "            single_patch_img = (single_patch_img.astype('float32')) / 255.       \n",
        "\n",
        "          dataset.append(single_patch_img)\n",
        "  return np.array(dataset)\n",
        "  \n",
        "def save_npy(npdata, filename):\n",
        "  np.save(f'/content/drive/MyDrive/DS-LAB1/{filename}',npdata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRXShRhlowy_",
        "outputId": "1c066dd8-797c-40e5-f517-b3edd0b24905"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "212"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# 1. Load train data and it's labels\n",
        "dataset = loadmat(file_path)\n",
        "train = dataset['train_data']\n",
        "train_labels = dataset['train_labels']\n",
        "train_data = train[:6]\n",
        "del train, dataset\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNROxyMruW9p",
        "outputId": "27d6b3a1-a493-4ed6-d34f-9dfbaaa95c06"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# 2. Reshape the data, generate patches and save it to file.\n",
        "train = reshape_data(train_data)\n",
        "del train_data\n",
        "dataset = data2patches(train, (patch_size,patch_size,6),patch_size,scaler)\n",
        "del train\n",
        "save_npy(dataset,'train_data')\n",
        "del dataset\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzFazDQXyP6z",
        "outputId": "0cf9efb5-a687-4d0c-f5ea-83a148bf1f9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(792, 256, 256, 19)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# 3. generate patches from train labels, generate one-hot encoding \n",
        "#    and save it to file.\n",
        "temp = data2patches(train_labels, (patch_size,patch_size),patch_size)\n",
        "train_labels_cat = to_categorical(temp, num_classes=19)\n",
        "print(train_labels_cat.shape)\n",
        "save_npy(train_labels_cat,'train_labels')\n",
        "del temp, train_labels, train_labels_cat\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wp8a69L13jtL",
        "outputId": "6bb5f303-0ea6-48e2-c205-09c02baf7648"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "52"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# 1. Load val data and it's labels\n",
        "dataset = loadmat(file_path)\n",
        "val = dataset['val_data']\n",
        "val_labels = dataset['val_labels']\n",
        "val_data = val[:6]\n",
        "del val, dataset\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7apvnqc3k0G",
        "outputId": "980c96fa-9d27-4ff3-d71b-ed90558690f1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# 2. Reshape the data, generate patches and save it to file.\n",
        "val = reshape_data(val_data)\n",
        "del val_data\n",
        "dataset = data2patches(val, (patch_size,patch_size,6),patch_size,scaler)\n",
        "del val\n",
        "save_npy(dataset,'val_data')\n",
        "del dataset\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcqvKBh_3lw4",
        "outputId": "eb9e4a36-7b4d-44f1-ea46-d32208d12ce3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(918, 256, 256, 19)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# 3. generate patches from train labels, generate one-hot encoding \n",
        "#    and save it to file.\n",
        "temp = data2patches(val_labels, (patch_size,patch_size),patch_size)\n",
        "val_labels_cat = to_categorical(temp, num_classes=19)\n",
        "del temp\n",
        "print(val_labels_cat.shape)\n",
        "save_npy(val_labels_cat,'val_labels')\n",
        "del val_labels, val_labels_cat\n",
        "gc.collect()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Generate Patches-RIT-18.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}